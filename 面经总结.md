# 一、C++的三大特性

## 概述

封装可以使得代码模块化，继承可以扩展已经存在的代码，他们的目的是为了代码重用。而多态的目的是为了接口重用。

## 封装

封装是设计类的一个基本原理，是将抽象得到的数据和行为相结合，形成一个有机的整体，也就是将数据与对数据进行的操作进行有机的结合，从而形成类，其中的数据和函数都是类的成员。

## 继承

如果B是继承了A，那么就把这个B称为是A的子类，把A称为B的父类。继承可以使子类具有父类的各种属性和方法和方法，就不用再次编写相同的代码。子类继承父类的同时，可以重新定义某些属性，并重定义其中的一些方法，也就是隐藏父类中原有的属性和方法，使其获得于父类不同的功能。

### 多继承

#### 菱形继承

菱形继承存在的问题就是数据二义性，相应的解决方案就是虚拟继承。

### 继承中的访问权限

父类的私有成员在子类中无论以什么方式继承都是不可见的，这个的不可见指的是private成员仍然被继承到了子类中，但是在语法上限制子类对象不管实在类内还是在类外都是无法访问它的。

子类以公有方式继承父类时，父类的成员在子类中保持原有的属性。

子类以保护方式继承父类时，父类中的公有成员在子类中成了保护成员。

子类以私有方式继承父类时，父类中所有成员在子类中都是私有的。

使用class时默认的继承方式时私有的，使用struct时则默认的继承方式是共有的。

还有一点就是友元是类级别的，不存在继承的问题，也就是子类不能继承父类的友元关系。

### 虚拟继承

## 多态

多态可以简单的概括为“一个接口，多种方法”，字面意思是多种形态。多态分为静态多态和动态多态。

### 静态多态

静态多态也称作静态绑定或者是早绑定。地址的绑定是编译器在编译的时候完成的，编译器根据函数实参的类型，可以推断出要调用那个函数，这里可能会进行隐式的类型转换，如果有对应的函数就调用了，否则编译报错。静态多态又分为函数重载和泛型编程。

#### 函数重载

函数重载是在相同的作用域中，只有函数的名称相同，参数个数或参数类型不同。编译器根据函数不同的参数表，对同名函数的名称修饰，然后这些同名函数就成了不同的函数。这个在C语言中是不支持的，因为c语言中对函数的名称修饰较为简单，在VS2013编译器中，c语言对函数名称修饰的处理只关注到了函数名，对函数名的修饰只是简单的在函数名前添加_，而c++语言除了函数名，还关注了函数的参数，对函数名的修饰时候要加上参数，通过对函数名称的修饰不同，编译器调用函数时所找的符号就不同。

#### 泛型编程

泛型编程指的是编写独立于特定类型的代码，泛型编程在C++中的主要是实现为函数模板和类模板。泛型编程的特性有如下几点：

1、函数模板并不是真正的函数，他只是C++编译器生成具体的函数的一个模子。

2、函数模板本身并不生成函数，实际生成的函数是替换函数模板的那个函数，这种替换在编译期就绑定了。

3、函数模板不是只编译一份满足多重需要，而是为每一种替换他的函数编译一份。

4、函数模板不允许自动类型转换。

5、函数模板不可以设置默认模板参数。

### 动态多态

C++中的动态多态是基于虚函数的。对于相关的对象类型，确定他们之间的一个共同的功能集，然后在父类中把这些共同的功能声明为多个公共的虚函数接口。各个子类重写这些虚函数，完成具体的功能。操作函数通过指向基类的引用或指针来操作这些对象，对虚函数的调用会自动绑定到实际提供的子类对象上去。

### 静态多态多态的比较

#### 静态多态

**优点**

1、静态多态通过模板编程为C++带来了泛型设计的概念,比如STL。

2、静态多态是在编译期完成的，所以效率很高，编译器可以对其进行优化。 

**缺点**

由于模板是实现静态多态,所以模板的不足也是静态多态的劣势,比如调试困难、编译耗时、代码膨胀。

#### 动态多态

**优点**

1、实现与接口分离，可复用。

**缺点**

1、运行时绑定，导致一定程度上的运行时开销。

2、编译器无法对虚函数进行优化。

3、笨重的类继承体系，对接口的修改影响整个类层次。

#### 不同点

##### **本质不同**：

早晚绑定，静态多态是在编译期决定的，由模板实现完成，而动态多态是在运行期间决定的，由继承、虚函数实现。

##### **接口方式不同**：

动态多态的接口是显式的，以函数名为中心，通过虚函数在运行期间实现，静态多态的接口是隐式的，以有效表达为中心，通过模板在编译期间完成。

##### **应用形式上**：

静多态是发散式的，让相同的实现代码应用于不同的场合。

动多态是收敛式的，让不同的实现代码应用于相同的场合。

##### **思维方式上**：

静多态是泛型式编程风格，它看重的是算法的普适性。

动多态是对象式编程风格，它看重的是接口和实现的分离度。

#### 相同点

够可以实现多态性，静态多态/编译期多态，动态多态/运行期多态。

都可以是使接口和实现分离，一个是模板定义接口，类型参数定义实现，一个是基类定义接口，继承类负责实现。

# 二、虚函数和纯虚函数★★

## 概述

之所以叫做虚函数，它虚就虚在所谓的“推迟联编”和“动态联编”上，一个类虚函数的调用并不是在编译时刻确定的，而是在运行的时候被确定。由于编写代码的时候并不能确定被调用的是基类函数还是那个派生类的函数，所以被称为虚函数。

虚函数只能借助指针或引用来达到多态的效果。常用的方式是基类指针或引用指向子类的对象。当有多个子类的继承时，可以统一用父类指针来表示各子类对象，但事实上所指的对象具体是哪一个，或者调用的函数是哪个子类中的函数，要在运行的时候才知道，这就实现了多态。

```c++
class parent
{
    public:
    	vritual void fun()
        {
            cout <<"parent::fun" << endl;
        }
};

class child :　public parent
{
	public:
		void fun()
		{
			cout << "child :: fun" << endl;
		}
};

int main()
{
    parent *a = new child;
    a->fun();		//这里的指针虽然是parent类型，但是指向的是child的fun函数。构成了多态。
    
    return 0;
}
```

## 语法

```c++
virtual void fun()=0;		//纯虚函数
virtual void fun();			//虚函数
```

## 纯虚函数

纯虚函数是指在基类中声明的虚函数，并没有在基类中定义，要求在任何派生类中都要定义自己的实现方法。在类中有纯虚函数的类被称为抽象类，由于他的构建并不完整，所以不能用抽象类来生成对象。继承了抽象类的派生类必须要将纯虚函数实现，否则同样是抽象类，不能生成对象。

## 虚函数表

虚函数表（以下称为虚表）是属于类的，不属于某个具体的对象，一个类中只有一个虚表，在同一个类中的所有对象都是用类中唯一这个虚表。为了指定对象的虚表，在对象构造的时候就在对象内部包含了虚表指针。为此编译器在类中添加了一个*_vptr来指向虚表，并且这个指针的值会自动被设置为指向该类的虚表。在C++编译器中，虚表指针在存放在每个对象的头四个字节，并且虚函数表的末尾是以空指针结束。

关于虚函数表有两种情况是要分清楚的，多继承和多重继承这两种继承中的虚表是不一样的。

多继承指的是有一个子类继承了两个基类，比如说有A，B，C三个类，在A和B类中都有虚函数，C类依次继承了A类和B类，这时候C类中的虚表就有了A类和B类两个虚表，并且C类中的虚表指针是以A类虚表地址为基础的，如果想要获取到B类虚表的地址可以让指针向后偏移A类的大小或者给出一个B类的指针指向C类对象发生一个天然的转换，需要注意的是在C类中的重写的虚函数会覆盖A类和B类中的同名虚函数，如果C类中的虚函数在A类和B类中没有，就添加到A类的虚函数表中，但是A类指针不可以调用，如果是只在A类或者B类中有的虚函数，在C类中没有，那么只能是拥有虚函数的父类和C类可以调用。

多重继承就是B类继承了A类，C类继承了B类，在B类中的重写的虚函数会在虚函数表中覆盖A类的同名虚函数，并将B类新添加的虚函数放在B类虚函数表的末尾，C类也是如此，C类的虚表是从B类中继承的，在C类中的重写的虚函数会在虚函数表中覆盖B类的同名虚函数，并将C类新添加的虚函数放在C类虚函数表的末尾。

# 三、引用和指针的区别

## 指针

对于一个类型T，T* 就是一个指向T的指针类型，也就是一个T*类型的变量能够保存一个T对象的地址，而类型T可以添加一些限定词，如const、volatile等等。

> volatile提醒编译器它后面所定义的变量随时有可能改变。精确地说就是，遇到这个关键字声明的变量，编译器对访问该变量的代码就不再优化，从而可以提供对特殊地址的稳定访问；如果不使用volatile，则编译器对所声明的语句进行优化。
>
> <1>中断服务程序中修改的供其他程序检测的变量需要加volatile；
>
> <2>多任务环境下各任务间共享的标志应该加volatile；
>
>  <3>多存储器映射的硬件寄存器通常也要加volatile，因为每次对它的读写都可能有不同意义。
>
> 需要注意的是：频繁地使用volatile很可能会增加代码尺寸和降低代码性能，因此要合理地使用volatile。

## 引用

引用就是一个对象的别名，主要用于函数参数和返回值类型，类型+&+变量名 = 被引用的对象。

## 不同点

1、引用是某块内存的别名，而指针指向的是一块内存，他的内容是所指内存的地址。

2、引用在创建时必须被初始化，但是指针可以为空，在C语言中NULL，在C++中是nullptr。所以指针在使用的时候必须要判空，引用就没有必要。

3、引用不可以改变指向，一旦初始化了，就不能改变。指针可以改变自己的指向，可以指向其他对象。

4、对于引用来说，const int &a 和 int& const a没有区别，因为都表示指向的对象是常量。对于指针来说，const int *p 说明p是指向常量的指针， int * const p 说明p本身就是一个常量。

5、引用的大小是指向对象的大小，而指针在32位机上是四字节，在64位机上是8字节，是指针本身的大小。

6、对引用++操作就是对引用指向的对象进行++操作，但是对指针++操作，表示的是地址的变化，向后移动一个指针的大小。

7、指针传递和引用传递

​		指针传递传递的是地址，在函数中定义了一个局部的指针变量，存放的是实参的地址，消耗了内存，可以对地址进行加减操作，指向另一个变量，由于传递的是地址，所以不需要返回值，因为实际修改的就是实参的值。

​		引用传递同样是地址，但是不会在函数中消耗内存，直接对地址进行使用，对函数中的引用变量的加减操作直接影响外部的实参，并且不能指向另一个变量。在实际使用中传递引用的时候如果不希望实参被改变，通常要用const将其修饰。

# 四、深拷贝和浅拷贝

​		浅拷贝指的是将原始对象中的数据型字段拷贝到新对象中，将引用型对象的引用赋值到新对象中去，不把引用的对象复制进去，所以原始对象和新对象引用同一对象，新对象中的引用型字段发生变化会导致原始对象中对应的字段发生变化。

​		深拷贝是在引用方面不同，深拷贝就是重新创建一个新的和原始字段内容相同的字段，所以两者的引用是不同的。其中一个对象发生变化并不会影响另一个对象。

编译系统会在我们自己没有定义拷贝构造的时候调用默认的拷贝构造函数，进行浅拷贝，也就是两个对象使用同一份资源。当两个对象调用析构函数的时候，就会析构两次，导致内存泄漏。所以对含有指针成员的对象或类中存在资源的对象进行拷贝的时候，必须要自己定义拷贝构造函数，实现深拷贝，避免内存泄漏。

# 五、TCP和UDP的区别及应用场景

## 区别

### 1、面向连接和无连接角度

tcp建立一个链接需要三次握手，断开的时候需要进行四次挥手。TCP在断开是主动方要进入一个TIME_WAIT状态，要等待2MSL才会对连接（端口）释放，这个时间要根据系统来定，Windows一般为120秒。

但是UDP不需要建立连接，直接发起。

### 2、可靠和不可靠角度

TCP利用三次握手、四次挥手、ACK确认应答、重传机制等来保证可靠性，UDP没有。

TCP中保证可靠性的机制有：

校验和：用来校验数据是否损坏

定时器：用来确认分组是否丢失，丢失需要重传

序列号：用来检测丢失的分组和重传的分组。

确认应答ACK：用来让接收方通知发送方已经正确接受，以及期望的下一个分组。

否定确认：用来让接收方通知发送方没有被正确接受的分组。

窗口和流水线：用于增加信道的吞吐量。

### 3、有序性

TCP利用seq序列号来对包进行排序，UDP没有

### 4、面向字节流和面向报文

##### 面向报文

面向报文的传输方式是应用层交给UDP多少报文，UDP就按原样发送，也就是一个发送一个报文。所以应用层就要选择合适的大小的报文交给UDP，如果报文太长，在IP层就会进行分片。

##### 面向字节流

面向字节流的传输方式是虽然应用层交给TCP的是一次一个数据块，但是TCP会将这个数据块看成一连串无结构的字节流。在TCP的发送端有一个发送缓冲区，当数据块太大，TCP就将它划分的小一些在发送，如果数据块太小了，TCP就会等待累计够足够多的字节后再发送。

##### 5、TCP有流量控制机制，UDP没有

##### 6、TCP头部为20字节，UDP头部为8字节

## 应用场景

### TCP的应用场景

对效率要求较低，但是对准确要求很高的场景。因为在使用TCP传输的时候需要对数据进行确认、重发、排序等操作，相对UDP来说效率降低了许多。这些场景都有：文件传输、远程登录。

### UDP应用场景

对效率要求较高，对准确要求较低的场景，因为在使用UDP传输的时候没有对数据进行任何的检验操作，相对于TCP效率提升了很多。这些应用场景有：QQ聊天、在线视频、广播通信等。

# 六、TCP连接的建立和断开★

## TCP建立连接

tcp采用三次握手建立连接，

1、客户端向服务端发起SYN连接请求，这条连接请求中还包含了客户端的窗口大小

2、服务端收到连接、请求后，为客户端申请资源同时向客户端回复一个SYN+ACK，还有自己的窗口大小。

3、如果这条消息丢失，客户端没有收到这条消息，那么客户端不会做任何响应，也就不会向服务端发送ACK确认，由于服务端迟迟没有发送确认的ACK，服务器就会将之前申请的资源释放。如果客户端收到了这条消息，开始申请资源，同时回复服务端一个ACK确认，开始进行收发数据。

4、如果最后这条ACK消息丢失，导致服务端没有收到，服务端就认为连接失败，将之前的资源释放，但是客户端认为连接已经建立好了，就会向服务端发送数据。服务端由于没有收到最后一条ACK消息，就会以RST包对客户端进行响应，重新建立连接。

## TCP断开连接

TCP采用四次挥手断开连接，

1、主动关闭方向被动方发送FIN请求，进入FIN_WAIT_1状态，等待被动方的ACK确认。  

2、被动接收到FIN请求后，回复一个ACK确认，这时被动方进入CLOSE_WAIT状态，进入这个状态是为了将自己的所有要发送的数据都发送完，将自己申请的空间都释放完。这时候主动方接受到ACK请求没有直接断开连接，而是进入FIN_WAIT_2状态，在这个状态下，主动方只能接受数据，不能进行发送。

3、等被动方将自己的事情都处理完，向主动方发送FIN请求，进入LAST_ACK状态，等待主动方的ACK确认。

4、主动方接收到被动方的FIN请求后，进入TIME_WAIT状态，向被动方发送ACK，等待2MSL后，进入CLOSED的状态。这里的MSL是一个报文在网络中的最大生命周期，进入TIME_WAIT状态，并且等待2MSL是为了防止由于网络原因，最后一个ACK没有到达被动方，如果被动方一直没有收到ACK确认，会再次向主动方发送FIN请求，这时主动方重新进入TIMR_WAIT状态。将等待时间设置为2MSL还有一个原因就是要将网络中所有残留的数据消失，防止由于网络原因某些数据阻塞在网络中，如果没有等待2MSL而是立即重新建立连接，很有可能之前的滞留在网络中的数据到达了，这时就会造成数混乱。如果在2MSL之内主动方没有接收到被动方FIN请求，则认为对方已经接收到ACK，主动方进入CLOSED状态，也就是断开连接。对于被动方来说，一旦接收到了来自主动方的ACK确认，就会进入CLOSED状态，关闭连接。

# 七、死锁的条件以及解决的办法

## 死锁的条件

必须要满足以下的四个条件才可以发生死锁。

### 1、互斥条件

指的是某个资源同时只能让一个进程占有，比如说打印机。必须要在占有该资源的进程主动释放资源后其他进程才可以占有。这时有资源本身属性决定的。

### 2、不可抢占资源

进程获得的资源在没有使用完的情况下，这份资源不能被资源申请者强行占有，只能等该资源释放候才可以申请。

### 3、占有且申请条件

一个进程至少占有了一个资源，他又要申请新的资源，但是申请的资源被另一个进程所占有，这时进程阻塞，在他阻塞的时候仍然占有已有的资源。

### 4、循环等待条件

可以说是一个进程等待队列，p1等待p2所占有的资源，同时p1不对自己的资源进行释放，p2在等待p1所占有的资源，同样的p2也不对自己所占有的资源进行释放，这样就形成了一个进程的循环等待。

## 死锁的预防

死锁的预防就是保证系统不进入死锁的状态的一种策略。

1、破坏互斥条件

但是有些资源确实不能被共享，这是由资源的属性决定的。

2、破坏不可抢占条件

将资源的申请设置为可抢占式，也就是要求申请失败的进程要释放自己占有的资源给其他进程使用，但是会降低系统性能。

3、破坏占有且申请条件

直接一次性将自己所需要的资源申请完。当时这样有两个问题，一个是有时候不可预知需要什么资源，另一个是资源的利用率低，进程可能会长期占有自己可能用不到的资源。

4、破坏循环等待条件

将资源进行分类、编号，让进程按照排好的序号进行申请。存在的问题是对资源的编号可能是困难的，维护相应的序列也可能是困难的。

## 死锁的避免

死锁的避免是指不限制进程有关申请资源的命令，而是对进程所发出的每一个申请资源命令甲乙动态的检查，并且根据检查结果来判断是否进行资源分配。

银行家算法：我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。 
为保证资金的安全，

银行家规定：

当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；
顾客可以分期贷款，但贷款的总数不能超过最大需求量；
当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；
当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.

操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量。若超过则拒绝分配资源，若能满足则按当前的申请量分配资源，否则也要推迟分配。



# 八、复杂度为O(longn)的排序有哪些？稳定吗？说一起其中的原理。

## 复杂度为O(logn)的排序

快排：不稳定

归并：稳定

堆排：不稳定

（讲归并）

```c++
void MergeData(vector<int>& arr, vector<int>& tmp, int left, int mid, int right)
{
    int begin1 = left, end1 = mid;
    int begin2 = mid, end2 = right;
    int index = left;
    while(begin1 <end1 && begin2 <end2)
    {
        if(arr[begin1] < arr[begin2])
            tmp[inedx++] = arr[begin1++];
        else
            tmp[index++] = arr[begin2++];
    }
    
    while(begin1 < end1)
        tmp[index++] = arr[begin1++];
    while(begin2 < end2)
        tmp[index++] = arr[begin2++];
    
}

void MergeSort0(vector<int>& arr)
{
    size_t size = arr.size();
    vector<int> tmp(size);
    size_t gap = 1;
    while(gap < size)
    {
        int right, left, mid;
        for(int i = 0; i < size; i = right)
        {
            left = i;
            mid = left + gap;
            right = mid + gap;
            MergeData(arr,tmp,left, mid, right);
            copy(tmp.begin()+left, tmp.begin()+right, arr.begin()+left);
        }
        
        gap *= 2;
    }
}

void _MergeSort(vector<int>& arr, vector<int>& tmp, int left, int right)
{
    if(right - left > 1)
    {
        int mid = (right - left)>>1;
        _MergeSort(arr, tmp, left, mid);
        _MergeSort(arr, tmp, mid, right);
        MergeData(arr,tmp,left, mid, right);
        copy(tmp.begin()+left, tmp.begin()+right, arr.begin() + left);
    }
}

void MergeSort1(vector<int>& arr)
{
    vector<int> tmp(arr.size());
    _MergeSort(arr, tmp, left, right);
}
```

# 九、介绍一下哈希表，哈希冲突怎么解决？

哈希表是根据关键码值而直接进行访问的数据结构。通过关键码值映射到表中的一个位置来访问记录，以加快查找的速度。哈希表主要是解决两个问题，哈希函数和哈希冲突。

## 哈希函数

哈希函数也叫散列函数，他对不同的输出值得到一个固定长度的消息摘要。理想的哈希函数对不同的输入要产生不同的结构，同时散列结果也应当具有同一性和雪崩效应（微小的输入值发生的变化使得输出值发生巨大的变化）。

## 哈希冲突

 哈希冲突就是不同的关键字通过相同的哈希函数计算出了相同的哈希地址。解决哈希冲突最常见的方法是闭散列和开散列，闭散列使用的是线性探测法，当发生哈希冲突时，如果哈希表没有被装满，说明可以将key值保存到下一个空位置中，从冲突发生的位置开始，依次向后探测，直到找到下一个空位置为止。开散列使用的是拉链法，先对关键码使用哈希函数计算哈希地址，具有相同的哈希地址的关键码归于同一个子集，称子集合为一个桶，每个桶中的元素通过一个单链表连接起来，然后将各个链表的头结点存放在哈希表中。由于哈希表中桶的个数是固定的，如果某个桶中的元素非常多，这样会影响真个哈希表的性能。一般来说如果桶中的元素过多，会将单链表的存储方式换成红黑树，或者是对哈希表进行增容。

# 十、二叉树的先序遍历、中序遍历和后序遍历

```c++
//二叉树的递归遍历

void PreOrde(BTree* root)
{
    if(root)
    {
        cout << root->data << " ";
        PreOrde(root->left);
        PreOrde(root->right);
    }
}

void InOrde(BTree* root)
{
    if(root)
    {
        PreOrde(root->left);
        cout << root->data << " ";
        PreOrde(root->right);
    }
}

void PostOrde(BTree* root)
{
    if(root)
    {
        PreOrde(root->left);
        PreOrde(root->right);
        cout << root->data << " ";
    }
}

void PreOrde1(BTree* root)
{
    stack<BTree*> s;
    BTree* cur = root;
    
    while(!s.empty() || cur)
    {
        while(cur)
        {
            cout << cur->data << " ";
            s.push(cur);
            cur = cur->left;
        }
        
        if(!s.empty())
        {
            BTree* tmp = s.top();
            s.pop();
            cur = tmp->right;
        }
    }
}

void InOrde1(BTree* root)
{
    stack<BTree*> s;
    BTree* cur = root;
    
    while(!s.empty() || cur)
    {
        while(cur)
        {
            s.push(cur);
            cur = cur->left;
        }
        
        if(!s.empty())
        {
            BTree* tmp = s.top();
            cout << tmp->data << " ";
            s.pop();
            cur = tmp->right;
        }
    }
}

void PasrOrde1(BTree* root)
{
    stack<BTree*> s;
    stack<bool> flag;
    BTree* cur = root;
    
    while(!s.empty() || cur)
    {
        while(cur)
        {
            s.push(cur);
            flag.push(false);
            cur = cur->left;
        }
        
        if(!s.empty())
        {
            if(flag.top())
            {
                cout << s.top()->data << " ";
                s.pop();
                flag.pop();
            }
            else
            {
                cur = s.top()->right;
                flag.top() = true;
            }
        }
    }   
}
```

# 十一、链表环

### 判断是否有环

定义一个快指针和一个慢指针，快指针一次走两步，慢指针一次走两步，会出现两种情况，情况一指针走到了空的位置，那就说明这个链表不带环。情况二两个指针相遇，说明这个链表带环。

### 获得入环节点

如果不考虑空间复杂度，可以使用一个map来记录走过的节点，这个指针一直向后遍历如果遇到空，说明这个链表不带环，也就没有入环节点，如果没有遇到空，如果遇到第一个在map中存在的节点，就说明回到了出发点，这个节点就是环的入口节点。

如果不建立额外的空间，先使用快慢指针判断这个链表是否有环，如果有环将相遇节点记录，然后一个指针从链表的起始位置开始一次走一步，另一个指针从记录的节点开始一次走一步，当两个节点再次相遇，这个相遇节点就是环的入口节点。

![1565675547490](C:\Users\LENOVO\AppData\Roaming\Typora\typora-user-images\1565675547490.png)



# 十二、栈和队列	

## 两个栈模拟实现队列

队列的特性就是只能在队尾进行插入操作，在队头进行删除操作，两个栈实现一个队列，一个栈s1负责入队列，另一个栈s2负责出队列，当删除队列的时候，如果s2中有元素，直接取栈顶元素，如果s2是空栈，将s1中的所有元素搬移到s2中，然后再取栈顶元素。

## 两个队列模拟实现栈

栈的特性就是只能在一端进行插入和删除操作，用两个队列一个用来进行入栈操作，另一个进行删除的时候才会用到，将有元素的栈的size-1个元素全部搬移到另一个空队列中，然后将最后一个元素删除，就完成了删除操作

# 十三、进程和线程

## 什么是线程？

线程是在Linux中使用PCB模拟实现的轻量级进程，进程从表面来说是一个运行起来的程序，但是从操作系统角度来说，进程就是操作系统堆为一个正在执行的程序而创建的描述符，操作系统通过对这个描述来对程序进行控制，这个描述信息就是PCB，所以说线程就是一个轻量级的进程，是一个进程等的子任务，线程共享进程中部分资源，包括数据段、代码段和扩展段，每个线程拥有自己的线程描述符、数据栈、用于存放上下文数据的寄存器、错误码、信号屏蔽字。进程是线程中的一个执行流，是操作系统调度和执行的最小单位。

## 线程和进程的区别？

1、一个线程只能属于一个进程，而一个进程可以有一个或多个线程，线程是依赖于进程存在的。

2、进程在执行过程中拥有一个独立的内存单元，而多个线程共享同一个进程的内存。也就是所资源分配给进程，在这个进程中的所有线程共享其中的所有资源，同一个进程中所有线程共享代码段、数据段、扩展段。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。栈寄存器（上下文数据）信号屏蔽字errno(错误码)线程标识符

3、进程是资源分配的最小单元，线程是CPU调度的最小单元

4、系统的开销：由于创建或撤销进程时，系统都要为他分配或回收，如内存空间、I/O设备等。因为操作系统所付出的开销将显著的大于在创建线程或撤销线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只需要保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作。所以进程切换的开销要远远大于线程切换的开销。

5、通信：由于同一个进程中的多个线程具有相同的地址空间，所以他们之间的同步和通信的实现也变得比较简单。进程间通信IPC有管道、共享内存、消息队列、信号量进行通信。线程间可以直接读写进程数据段来进行通信。在有的系统中，线程的切换、同步和通信都无需操作系统内核干预。

6、进程编程调试简单可靠性高，但是创建和销毁的开销较大，相对于线程来说正好相反，开销小、切换速度快，但是编程调试相对复杂。

7、进程之间不会相互影响，但是同一个进程中只有一个线程挂掉了将导致整个进程挂掉。

8、多线程适合于I/O密集的工作场景、多进程适合于CPU密集型的工作场景。

## 怎么实现线程池？

1、设置一个生产者消费者队列，作为临界资源。

2、初始化n个线程，并让其运行起来，以加解锁的方式去队列取任务运行。

3、当任务队列为空的时候所有的线程阻塞。

4、当生产者队列来了一个任务后，先对队列加锁，把任务挂在队列上，然后使用条件变量去通知阻塞中的一个线程。

# 十四、socket编程过程

## 基于TCP的socket：

#### 服务端程序：

```c++
创建一个socket，调用socket（）函数，返回
绑定IP地址、等信息到socket上，调用函数bind（）
设置允许的最大连接数,调用函数listen()，通常设置为5
接受来自客户端的连接，调用accept(),
使用send和recv开始收发数据
关闭网络连接
```

#### 客户端程序

```c++
创建一个socket，调用socket()函数
设置要连接的对方的IP地址和端口等属性
连接服务器，调用函数connect()
使用send和recv开始收发数据
关闭网络连接
```

![img](https://uploadfiles.nowcoder.com/images/20190315/308571_1552654678444_69CF8398BCC9F204991E623723D022E7)

## 基于UDP的socket

#### 服务端流程

```c++
创建套接字文件描述符，调用socket();
设置服务器地址和监听关口，初始化要绑定的网络地址结构。
绑定监听端口，调用bind()函数，
接收客户端数据，调用recvfrom()函数
向客户端发送数据，调用sendto()函数向客户端发送数据
关闭套接字，调用close()函数释放资源。
```

#### 客户端流程

```c++
创建套接字文件描述符，调用socket()
设置服务器地址和端口，struct sockaddr()
向服务端发送数据，调用sendto()，
接受服务端的数据，调用recvfrom()
关闭套接字，调用close()函数释放资源。

```



# 十五、类中的成员函数占空间吗？怎么去调用？

类中的普通成员函数和静态成员函数是不占用类的内存的，只有在类中含有虚函数的时候才会在类中添加一个虚函数指针，增加一个指针的大小。类中的成员函数实际上与普通的全局函数一样，只不过是在编译的时候在成员函数中添加一个指向当前对象的this指针，成员函数的地址是全局已知的，所以对象的内存空间中没必要去保存成员函数的地址。对于普通成员函数来说，在编译的时候就已经确定了，类的属性指的是类中的数据成员，他们是实例化一个一个对象的时候就为数据成员分配了内存，但是成员函数是所有对象所共有的。

# 十六、动态库和静态库

### 什么是库？

平时在写代码的时候会经常添加一些头文件，添加这些头文件其实是让编译器从一个目录下去寻找这个文件，这个目录就是我们常说的库。在Linux中库一般存放在user/lib目录。库就是将一些常用的函数的目标文件打包在一起，提供相应的函数接口，以便于使用。

### 什么是静态库？

静态库就是在编译连接的时候，将库中的代码连接直接复制到可执行文件中，这样程序在运行的时候就不用去连接动态库了。静态库的这个连接过程就是静态链接。

### 什么是动态库？

动态库就是程序在运行的时候才去连接动态库的代码，可以多个程序共享动态库中的代码，这个动态库的连接过程就是动态链接，也就是在执行文件开始之前将外部函数的机器码有系统从磁盘上对应的动态库中向内存复制一份。

### 静态库和动态库的区别？

1、动态库是在运行时有系统调用库函数实现链接，代码较小巧。而静态库是在链接是复制到代码中，代码量比较庞大，冗余度高。
2、由于静态库是通过复制的方式，所以他在编译连接之后就不再需要静态库，代码的可以执行强，但是动态库由于是利用本地的库函数，如果将代码移植到其他电脑会出现运行bug等，可移植性差。
3、动态库必须放在**指定的目录**下完成连接，但是静态库只需要给出链接**文件的路径**就可以。
4、他们的相同点就是在库文件中不能出现main函数，库都是用来提供函数接口的，不暴露源代码，所有的库的目的都是为了增加代码的复用，可共享性，减小冗余。
5、在windows中静态库是后缀是.lib，动态库是.dll，在Linux中静态库是.a,动态库是so。
6、使用ar创建静态库

### 生成动态和静态库

​			gcc	-fPIC	-c	child.c	-o	child.o	生成目标文件

​			gcc	--share	child.o	-o	lid+库名称+.so			动态库

​			gcc	-cr		lib+库名称+.a										 静态库

​			windows下的动态库		.dll		静态库		.lib

# 十七、协程

协程可以认为是比线程更小的执行单元，它自带CPU上下文，只要在合适的时机，就可以把一个协程切换到另一个协程，只要在这个过程中保存或恢复CPU上下文那么程序还是可以运行的。
线程与协程的区别就是系统为了程序运行的高效性每个线程都有自己缓存Cacge等数据，操作系统还会帮助做这些数据的恢复操作，可以说线程的切换时非常耗性能，但是协程的切换只是单程的操作CPU的上下文，所以一秒钟切换上百万次系统都扛得住。但是协程有一个问题就是系统并不感知，所以操作系统不会对其做切换。在设计的时候可以是一个线程作为容器，然后再里面放置多个协程，构成一个协程池，在协程池中有一个被动的调度器，当有协程执行不了的时候，就要去通知协程调度器通过算法找到当前最需要CPU的协程，然后去执行。

# 十八、网络模型中每一层的协议

## 应用层的协议

基于TCP的有FTP、Telnet、SMTP、HTTP、POP3与DNS
基于UDP的有TFTP、SNMP与DNS
其中DNS既可以基于TCP，也可以基于UDP。

> FTP(File Transfer Protocol)：文本传输协议 **端口号： 20 和21一个端口用于控制，一个端口用于传输数据**
>
> Telnet：**端口号为23**，功能：远程管理，而在Linux中为SSH **端口号为22**
>
> SMTP: 发送邮件 TCP：25 
>
> POP3：接收邮件TCP:110
>
> HTTP:超文本传输协议 TCP:80 
> HTTPS：相对于HTTP安全 对数据包进行加密 TCP：43
>
> DNS：域名解析服务 网络下标如果出现谈好很可能是DNS配置不对 TCP UDP:53
>
> TFTP：简单文件传输协议 早先FTP服务器代码太大了相对于服务器的容量来说，所以主要传输一些小文件的时候就是用TFTP，**对于网络设备的维护一直使用** **端口号为69**

## 传输层的协议



## 网络层的协议

## 链路层的协议

## 物理层的协议

# 十九、怎么让客户端和服务端一直保持连接

通情况下tcp的连接是一直保持很长时间，但是有可能这个链接会一直空闲着，这样会造成资源浪费，所以TCP就提供了保活机制和心跳报文

### 保活机制

也就是keepalive，在客户端和服务端都可以设置，通常是服务端设置的。保活时长一般是2小时，如果这个tcp连接空闲了两个小时，这个保活计时器超时，服务端会向客户端发送一个探测报文，这时客户端通常处于这么几个状态。

1、客户端处于正常状态，收到探测报文后发送了响应报文，服务端知道客户端是正常的，将保活计时器复位。

2、客户端已经崩溃，正在关机或者重启，没有响应服务端的探测报文， 服务端由于没有收到回复，会每个75秒发送一个探测报文，如果连续发送10探测报文都没有响应，就会认为客户端挂了，会关闭TCP连接。

3、客户端已经重启，并且正常运行了，但是在重启之前关闭了tcp，这个客户端收到探测报文，回应一个RST，服务端收到这个报文将TCP连接关闭。

4、客户端正常运行，但是接收不到服务端的报文，可以说是和情况2是一样的，服务端并不能去放是网络问题还是客户端的问题，所以同样会将连接关闭。

### 心跳报文

每隔一段时间向对端发送一个较小的数据包，通知对方自己在线，并传送一些可能必要的数据包，并且定时检测对端返回的数据，如果连续几次没有在规定的时间中收到回复，则判断对端已经掉线，然后做进一步处理，这个方法适合客户端，在应用层开一个线程发送心跳包，检测对端情况。

# 两个数组各有一万个数，怎么查找相同的数？

# 二十、hashmap和map的区别？

map是STL中的一个关联式容器，它提供一对一的K-V的数据处理能力，由于这个特性，在我们需要完成Key-Value数据处理的时候可以很方便的调用。map的底层结构是红黑树，这棵树对数据有自动排序的功能，所以map中的数据都是有序的，并且查找的时间复杂度基本是LogN。他的特点是增加和删除节点对迭代器的影响很小，只对操作的节点有影响，但是对于迭代器来说，可以修改节点对应的V值，不能修改K值。

HashMap是基于哈希表的Map，它具有着map的特性。当我们将K值传递给put()方法时，它调用对象的hashCode()方法来计算hashcode，然后找到对应的位置来存放value。hashmap使用开散列的方法来解决哈希冲突。他是线程不安全的，hashmap中的初始容量和装填因子会影响他的性能。

1、他们的底层实现不同，map使用的是红黑树来实现，Hashmap使用的哈希表来实现。

2、他们的查找时间复杂度不同，map的时间复杂度是log(n)，hashmap的时间复杂度O(1)。

3、map不允许有NULL值，但是hashmap允许有NULL。

# 二十一、STL总结

## 什么是STL

STL是一套高效的C++程序库，采用泛型编程的思想对常见的数据结构和算法进程封装，里面处处体现着泛型编程的设计思想以及设计模式，现在已经被集成到了C++标准库中。STL里面包含了容器、适配器、空间配置器、迭代器、仿函数和算法。

其中容器分为序列容器和关联式容器两大类，序列容器包括静态数组array、动态数组vector、动态二维数组deque、带头结点的循环单链表forward_list、带头结点的双向循环链表list、字符串string。关联式容器根据地层的实现红黑树实现和哈希表实现两大类，关联式容器中的两大类主要区别于底层的实现，红黑树和哈希表，

红黑树是一种二叉搜索树，在每个节点上都增加了一个存储位表示结点的颜色，可以红色或者是黑色，通过对任何一条从根到叶子结点的路径上各个节点的颜色限制，确保没有一条路径会比其他路径长出2倍，所以是接近平衡的，是比较稳定的二叉搜索树，由于二叉搜索树的任意根节点总是大于它左子树的所有节点，小于他的右子树的所有节点，所以在查找的时候可以采用类似于二分查找的思想，快速找到某个节点，红黑树是一个平衡二叉树，他的查找时间复杂度也是logN。

哈希表是根据关键码值直接进行访问的数据结构。通过关键码值可以直接映射到哈希表中的一个位置来访问对应的值，以加快查找的速度，查找的时间复杂度是O(1)。哈希表 	主要解决的是哈希函数和哈希冲突，哈希函数也叫散列函数，要根据不同的输入值得到一个固定长度的消息摘要。理想的哈希函数要对不同的输入产生不同的不同的输出结果，同时还要满足同一性和雪崩效应。哈希冲突就是不同的关键码值通过哈希函数计算出相同的哈希地址。

解决哈希冲突的常见方法有闭散列和开散列两种，闭散列采用的是线性探测法，当发生哈希冲突时，如果哈希表没有被装满，就说明还可以将关键码值存放到下一个空位置，然后从冲突位置一次向后探测，直到空位置为止，闭散列可以缓解哈希冲突，但是不能彻底解决。开散列使用的是拉链法，先将关键码通过哈希函数计算得到相应的哈希地址，然后将相同的哈希地址的关键码放在同一个子集合中，这个子集合通常称之为桶，每个桶中的元素通过单链表的方式连接起来，然后将各个链表的头结点存放在哈希表中。

但是对于哈希表来说通的个数是固定，如果某个桶中的元素超过了8个，就要将这个桶中的单链表转换为红黑树，如果桶中的元素小于6个的时候要将红黑树结构再次转换为单链表。这个转换是由于桶中的元素是由链表保存的，链表的查找时间复杂度是O(N)，而红黑树的查找时间复杂度是logN，但是当链表中的长度很小的时候，查找也是很快的，当链表不断变长了他的查找性能就会降低，需要转换成红黑树。一开始不将桶的结构初始化为树是因为一个红黑树的节点占用的空间是单链表节点的二倍，为了时间和空间的权衡只有当链表长度到8才进行单链表向红黑树的转换。但一个哈希表的离散性很好的情况下，将单链表转换为红黑树的概率很小，因为数据均匀分布在每个哈希桶中，几乎不会有哈希桶中的链表长度达到8，理想情况下哈希表中的所有哈希桶中节点分布频率会遵循泊松分布，长度为8的概率是6*10^-8，几乎是不可能的。

hash和红黑都是性能非常高的两个数据结构，但是他们还是有区别的，hash的查找速度比红黑树快，并且查找速度基本上是和数据量无关的，属于常数级别，但是红黑树的查找速度是logN的，但是hash还有hash函数，并且它的构造速度也是比较慢的，并且还需要实现分配足够的内存存储散列表，并且hash是无序的。红黑树所需要的内存较小，只需要为节点分配内存，并且红黑树中的节点是有序，它的查找时间复杂度是LogN，但是不能说就比常数大。基于这两个数据结构各自的特点和性能，STL将关联式容器分成了基于红黑树的map、set、multimap、multiset和基于hash的unordered_map、unordered_map、unordered_set、unordered_multimap、unordered_multiset。

## vector

vector是线性容器，他的元素严格按照线性序列排序和动态数组很相识，他和数组一样，所有的元素存储在一块连续的存储空间中，这也意味着我们不仅可以使用迭代器访问元素，还可以使用指针偏移的方式访问，和常规数组不一样的是，vector能够自动存储元素，可以自动增长和缩小存储空间。和数组相比，虽然vector在在自动处理容量的大小时会消耗更多的内存，但是容器可以提供和数组一样的性能，而且可以很好的调整存储空间的大小。相比其他的序列容器，能更有效地访问容器中的元素和在末尾添加和删除元素，在其他位置添加和删除元素就不如其他序列容器了，并且在迭代器当面也不如list支持的好。

vector的迭代器，无论在迭代器位置进行增加元素还是删除元素都会导致所有的迭代器失效，因为vector中删除和添加元素后可能会改变容器的大小，所以要更新所有的迭代器，关于vector的空间这里需要注意的是size和capacity这两个成员函数的区别，size指的是当前容器中拥有元素的个数，而capacity指的是当前容器可以存放的元素个数。vector在分配空间这块他会分配一些额外的空间来适应可能的增长，因为存想 GVC C  DD储空间比实际需要的存储空间更大。不同的库采用的不同的策略权衡空间的使用和重新分配，在vs中PJ版本的STL是以1.5倍的方式进行扩容的，在gcc中的SGI版本的STL是按2倍的方式进行扩容的。

## list

list是可以在常数范围内在任意位置进行插入和删除的序列式容器，并且该容器可以向前向后双向迭代。list的地层是一个双向链表结构，双向链表中每个元素存储在互不相关的独立节点中，在节点中通过指针指向其前一个元素和后一个元素。他与forward_list非常相似，最主要的区别就是forward_list是单链表，只能向后迭代，而list是双向链表，可以向前迭代也可以向后迭代。与其他容器相比较，list和forward_list最大的缺陷就是不支持在任意位置的随机访问，比如：要访问list的第6个元素，必须从头部或者尾部迭代到该位置，这段位置上的迭代需要线性的时间开销，list还需要开辟一些额外的空间，以保存每个节点相关联的信息。

list中也存在迭代器失效的问题，因为list的底层结构是双向循环链表，所以在list中插入时不会导致list的迭代器失效，只有在删除的时候才会导致迭代器失效，但是失效的仅是被删除节点的迭代器，其他的迭代器并不会受到影响。

#### vector和list的区别

##### 底层结构

vector是动态的顺序表，在内存中是一段连续的空间，list使用的是带头结点的双向循环链表。

##### 随机访问

vector支持随机访问，访问某个元素的时间复杂度是O(1),list不支持随机访问，访问某个元素的时间复杂度是O(n)

##### 插入和删除

vector在任意位置的插入和删除的效率较低，需要搬移元素，时间复杂度为O(N)，插入的时候还有可能会增容，增容操作中有开辟新空间、拷贝元素、释放旧空间，导致效率更低。list在任意位置插入和删除效率比较高，不需要搬移元素，只需要更改上下两个节点的指针指向，时间复杂度是O(1)。

##### 空间利用率

vector的底层为一段连续的空间，不容易造成内存碎片，空间利用率高，缓存利用率高。list底层节点动态开辟，容易造成内存碎片，空间利用率低，缓存利用率低。

##### 迭代器

vector使用的是原生态的指针，list是将原生态的指针进行了封装。vector在插入元素是要给所有的迭代器重新赋值，因为插入元素有可能会导致扩容，致使原来的迭代器会失效，并且删除元素的时候也会对迭代器进行重新赋值，同样也会使原来的迭代器失效。对弈list来说，他的底层是双向循环链表，插入元素时并不会导致迭代器失效，删除元素是只会导致当前的迭代器失效，其他的迭代器并不受影响。

##### 使用场景

vector适用于需要高效存储，需要随机访问，并且不关心插入和删除的效率。list适用于大量的插入和删除操作，不需要随机访问，也不关心存储的场景。

### set

set是按照一定次序进行存储的容器。set中元素只有一个value，并且每个value必须是唯一的，set中的元素不能再容器中进行修改，元素总是const的，但是可以容容器中对他们进行删除或者插入。并且元素总是按照其内部的比较对象所指是的特定的严格弱排序标准进行排序的，set访问元素的速度要比unordered_set慢，但是它允许直接迭代，并且是有序的，set的底层实现是红黑树。他与map/multimap不同的是set中只存放的value，但是他的底层存放的是由<value value>构成的键值对，由于set中不允许有重复的元素，所以可以使用set去重，

### map

map是关联式容器，他按照特定的次序来存储由建值key和值value组合而成的元素。在map中，建值key通常用于排序和唯一标识元素，而值value中存储的是与建值key相关联的内容。建值key和值value的类型可能不同，并且在map中，key与value通过成员类型value_type绑定在一起。在map中，元素总是按照建值key进行比较排序，并且他访问某个元素时通常要比unordered_map慢，但是map中的元素直接进行迭代是有序的。他的底层实现是红黑树结构。map与multimap唯一的不同就是map中的key值是唯一的，但是multimap中的key是可以重复的。set于multiset的区别就是multiset中的元素是可以重复的。

### list、set、map的区别

从结构上来说

list和set是存储的单列数据的集合，map中存储的是键值对这样的双列数据的集合。list的底层结构是双向循环列表，set和map的底层结构是红黑树。

从数据上来说

list中存储的数据是有顺序的，并且是允许有重复的，查找的时间复杂度是O(N)，每个节点只有一个值value；map中的存储的数据是无序的，他的键值是不允许重复的，但是他的值是允许重复的，并且他的键值是有序的，查找时间复杂度是logN，每个节点是由键值key，值value构成的键值对，set中存储的数据是有序的，不允许重复，查找时间复杂度是logN，每个节点是值value，但是他的底层节点是value,value的键值对。

### hashmap

vector和list的区别

map和set的区别

map和undored_map的区别

 迭代器的萃取不能   不能

1. 说说你所知道的容器都有哪些？
2. map与set的区别？使用map有哪些优势？
3. map的底层实现，说下红黑树？
4. map的迭代器会失效吗？什么情况下回失效？
5. AVLTree和RBTree的对比，为什么map和set使用了红黑树？红黑树的优势是什么？
6. AVLTree和RBTree所达到的平衡有什么区别？
7. RBTree节点的颜色是红或者黑色？其他颜色行不行？
8. RBTree是如何插入？如何旋转的？



# 二十二、类型转换

# 二十三、智能指针

### 什么是智能指针？

智能指针最主要的作用就是管理一个指针，因为有可能申请的空间在函数结束的时候没有及时的释放，从而造成的了内存泄漏。使用智能指针是要是针对这个问题，因为只能指针是一个类，在他生命周期结束的时候回去调用析构函数进行资源的释放，不需要进行手动的释放资源。智能指针一共有auto_ptr、unique_ptr、shard_ptr、week_ptr四种。

auto_ptr：

是C++98提出来的智能指针，它采用的是所有权模式。就是将智能指针A赋值给智能指针B，就是将A的所有权交给了B，如果再想访问A就会出错，auto_ptr的缺点就是存在潜在的内存崩溃问题。

unique_ptr

他解决了auto_ptr的问题，从名字可以知道他是独有的智能指针，也就是说他不能进行赋值和拷贝操作，在unique_ptr中将拷贝构造函数和赋值运算符重载私有，并且将其删除。

shared_ptr

shared_ptr实现了共享的概念，多个智能指针可以指向同一份资源。他的原理是多个智能指针共同维护一份引用计数，当有第二个进行赋值和拷贝构造的时候回将引用计数+1，每当一个智能指针使用完需要调用析构函数的时候就会检查是不是最后一个使用资源的，如果不是不进行释放，否则要进行资源释放。但是在使用的时候会出现这么一个情况，就是相互引用产生的死锁问题，那么这两个智能指针的引用计数将永远不会下降为0，也就是资源不会得到释放。这时就需要week_ptr了。

week_ptr

week_ptr是一种不控制对象生命周期的智能指针，他指向一个sheard_ptr管理的对象，进行该对象的内存管理的是那个强引用的shared_ptr。week_ptr只是提供了对管理对象的一各访问的手段，他只能从一个shared_ptr或另一个weak_ptr对象构造，他的构造函数和析构函数是不会引起引用计数的改变。week_ptr只能是协助shared_ptr，他不能直接指向对象。

# 二十四、红黑树

什么是红黑树？

他的查找时间复杂度为什么是log(n)？

# 二十五、AVL树

# 二十六、static

static有静态局部变量、静态全局变量和静态方法三种用法，他们的共同点就是在本文件中的声明的静态变量和静态方法是不能被其他文件所使用的，和他相对应的是extern关键字，extern关键字声明的全局变量和函数在整个工程中都可以使用。

## static全局变量

由static声明的全局变量，只能在函数体的外部被定义，并且只能在本文件中有效，这点就区别于普通的全局变量，普通的全局变量在其他文件中也是可见的。在函数体中可以定义同名的局部变量，会替代这个静态的，这时候如果想继续使用静态的全局变量，就需要在变量名前添加作用域运算符。

## static局部变量

static局部变量也是只能在本文件中使用，静态局部变量的生命周期不随着函数的结束而结束，只能在第一次调用函数的时候对他进行初始化，之后调用就会跳过初始化，他会在函数结束后在内存中保存当前的结果，而不是销毁，在内存中他区别于普通局部变量的是局部变量每次调用函数分配的内存空间可能不一样，但是静态局部变量具有全局唯一性的特点，每次调用使用的都是用一块内存空间，但是这也造成了一个不可重入的问题。比如说现在有两个线程AB都要去调用这个函数func（），如果线程A在调用函数fun()的，在运行函数的时候失去了运行权，但是已经对其中的局部静态变量修改为要使用的值，由于是使用的同一块内存空间，线程B调用函数后同样将局部静态变量修改成了自己要使用的值，那么当线程A继续执行时，由于这块内存空间中的值已经被修改了，线程A就不能得到想要的结果。

## static数据成员和成员函数

在C++中继承了C语言的static这个关键字，并在类中给了第三种定义方法：表示属于一个类而不是属于类中的人员和一个特定的对象的变量和函数，这个和普通成员函数的最大区别，他对整个类来说是唯一的，所以不属于某个实际的对象。对于静态数据成员来说，无论函数是不是静态的，他在内存中都只有一份，普通成员函数调用的时候需要传入this指针，但是静态成员函数调用时没有this指针，只能在调用的时候使用类名加作用域来调用。在设计多线程操作的时候，由于posix库下的线程函数要求是全局的，所以普通成员函数无法直接作为线程函数，但是静态成员函数可以做线程函数。

## static函数和普通函数

普通函数的定义和声明默认是extern的，在共一个工程中的其他文件中是可见的，如果在另一个文件中也定义了相同的函数，就会出现重定义错误，当然这个重定义和继承中的重定义是不一样的，这个指的是命名冲突。

静态函数在内存中只有一份，但是普通函数在每个被调用中都会维持一份拷贝。

# 二十七、select、poll、epoll的区别

## select

对大量的IO事件是否就绪进行监控，并且可以告诉进程哪一个IO就绪了，然后就可以对就绪的IO进行具体的操作。事件是否就绪指的是文件描述符可读/可写/异常。他的流程是这样的：用户将需要监控的文件描述符添加到一个描述符集合中，然后select将描述符集合拷贝到内核中，对集合中的描述符进行轮询判断，如果有描述符事件就绪了，select调用返回，并且返回描述符的个数。否则隔一会再进行轮询判断。在调用返回之前会将集合中没有就绪的时间描述符移除，在集合中只剩下就绪的文件描述符。返回之后进程判断有哪个文件描述符在集合中，然后对其进行操作。

#### select的缺点

select所能监控的文件描述符最多只有1024个，他每次都需要将文件描述符集合拷贝到内核中进行监控，在用户态和内核态之间进行数据的拷贝，在内核中要对所有的文件描述符进行轮询遍历判断，性能会随着描述符的增加而降低，每次返回的时候都需要将文件描述符集合中非就绪的描述符进行移除，再次监控的时候需要添加新的描述符，编码复杂，select虽然返回给用户文件描述符集合，但并不会告诉用户哪些文件描述符是就绪的，需要用户自己去遍历判断，性能同样会随着描述符的增多而降低。

#### select的优点

select遵循posix标准，可以跨平台使用，并且他监控超时的等待时间可以精细到微秒。

### poll

poll的功能也是对大量的文件描述符事件进行监控，用户为每一个关心的文件描述符定义一个事件结构，内容为文件描述符+所关心的事件，poll将描述符事件结构数组拷贝到内核中进行监控，同样是轮询遍历数组中的描述符判断事件是否就绪，如果就绪了就将事件放到事件结构revents中，调用返回，否则会隔一段时候后继续遍历判断，当调用返回后，用户遍历事件结构数组，判断结构中的revents事件中是否包含了所关心的事件。

#### poll缺点

每次监控需要将所有的事件结构信息拷贝到内核中，在内核中进行轮询判断描述符事件是否就绪，会随着描述符的增多而降低性能，poll的返回同样不会直接告诉用户哪些描述符就绪了，需要用户轮询去遍历事件结构数组，判断哪个是用户所关心的，并且对其进行操作，poll相对于select来说没有大的改变，性能并没有提升多少，并且poll没有遵循POSIX标准，所以不能跨平台。

#### poll优点

poll采用事件结构的方式对描述符进行监控，简化了多个描述符集合的监控编码流程，poll监控的文件描述符的数量没有上限。

### epoll

epoll可以说是Linux中最优秀的多路转接，他的性能是最高的，他在内核中创建eventpoll结构体，这个结构体是由红黑树（存放事件节点）和双向链表（存放就绪的文件描述符）实现。在**linux2.6.8**之前需要对epoll监控的文件描述符数量上限进行设置，但是在Linux2.6.8之后就忽略了这一参数，只要大于0就可以。epoll是一个异步操作，epoll开始监控后，告诉操作系统开始进程监控eventpoll结构体中红黑树中的所有事件节点，操作系统为每一个文件描述符就定义了 一个事件回溯，当文件描述符指定的事件就绪后，就将这个描述符指定的事件接收信息节点添加到eventpoll中的双向链表中。相当于直接告诉了用户哪些文件描述符就绪了。

#### epoll触发方式

**水平触发**

对于可读事件来说，文件描述符接收缓冲区数据大小只要大于低水位标记就会触发，对于可写事件来说只要是文件描述符的发送缓冲区空间大小只要大于低水位标记就会触发。水平触发是epoll的默认触发方式，EPOLLLT宏；

**边缘触发**

对于可读事件来说，描述符缓冲区中每当有新数据到来时才会触发一次，对于可写事件来说描述符发送缓冲区从没有剩余空间到有剩余空间时才会触发一次。边缘触发需要手动设置，EPOLLET。边缘触发每条数据值触发一次，这就意味着这次触发的过程中需要用户将所有的数据存取完毕，因为这条数据不会触发第二次，只有等到下一条数据到来才会触发下一次。由于边缘触发需要一次性将所有的数据都处理完，但是用户有可能也不知道数据有多长，所以要使用循环才可以将所有的数据处理完，但是循环会出现一个就是读到没有数据的时候就会阻塞。相应的解决方案是将IO操作设置为非阻塞的。

```c++
将描述符设置为非阻塞：
int flag = fcntl(fd, F_GETFD,0) ----获取描述符属性
fcntl(fd, F_GETFD, flag | O_NONBLOCK)---设置描述符属性为增加一个非阻塞属性

```

#### epoll优点

监控的文件描述符没有上限，采用事件结构对描述符进行监控，简化了多个描述符集合的监控流程，每条epoll的事件信息只向内核中拷贝一次，是一个异步阻塞操作，操作系统仅对描述符事件进行监控，并且使用的是事件回调方式，描述符就绪后直接拷贝到对应的位置，不需要轮询遍历判断，所以描述符的增加不会影响性能，在回调的过程中是将就绪的描述符添加到双向链表中，epoll_wait只需要判断双向链表就知道当前是否有描述符事件就绪，当epoll_wait返回时，是直接将就绪信息拷贝到之前给予的事件结构数组中，这就相当于直接将就绪的描述符告诉给了用户。

#### epoll缺点

epoll没有遵循POSIX标准，所以不能跨平台，他监控超时只能精确到毫秒。

### 同步异步和阻塞非阻塞的区别

阻塞是为了完成一个功能发起调用，如果当前不满足条件，要等待满足条件了才调用返回。非阻塞恰恰相反，如果不满足条件直接报错返回，阻塞和非阻塞强调的是发起一个调用后是否立即返回。同步指的是如果不满足条件需要进程进行等待，知道条件满足了才会调用返回，对于异步来说，他为了完成某个功能只发起一个调用，进程自身并不去完成，功能有操作系统完成后调用进程，所以说同步和异步强调的是发起调用后，功能是否有进程自己完成。同步功能是由进程自身完成的，通常是阻塞的，异步功能是由系统完成的，有阻塞也有非阻塞。

### 场景

多路转接模型实现高并发模型相较于多线程/多进程消耗资源较少，但并不是说所有的场景都使用多路转接模型，它只是用于有大量的文件描述符需要监控，但是同一时间只有少量活跃，并且每个描述符的处理过程时间不能太长。



# 二十八、用户态和内核态



# 二十九、什么是POSIX标准？

# 三十、hashmap 和 hashtable的区别

# 三十一、索引和事务

# 三十二、红黑树

# 三十三、进程的同步

为了能有效的控制多个进程之间的沟通过程，必须要有一定的同步机制保证进程之间不会自说自话而是有效的协同工作。比如在进程通信中的共享内存通信方式中，两个或多个进程都要对共享的内存进行数据的写入，这时候就需要同步来保证一个进程在写入数据的过程不会被其他进程所打断，保证数据的完整性。常用的同步方式有互斥锁、条件变量、读写锁、记录锁（文件锁）。

## 互斥锁

互斥从表面上理解就是相互排斥。所以互斥锁从字面上理解就是一个进程拥有了这个锁，他将排斥其他所有的进程访问被锁住的东西，其他的进程如果需要锁只能阻塞等待，等拥有锁的进程解锁后才能继续运行。在使用互斥锁的时候要注意一点就是解铃还须系铃人，如果拥有锁的进程不解锁，那么其他进程将永远不能得到互斥锁。

## 条件变量

条件变量是一种同步机制，允许线程挂起，直到共享数据上的某些条件得到满足。条件变量要和互斥锁相结合，避免出现条件竞争，就是一个线程预备等待一个条件变量，当它在真正等待之前，另一个线程恰好触发了该条件。

## 读写锁

互斥锁是排它锁，条件变量出现后和互斥锁配合能够有效地节省系统资源并提高线程之间的协同工作效率。互斥锁的目的是为了独占，条件变量的目的是为了等待和通知。对于文件来说，最常见的操作就是读和写，读文件不会修改文件的内容，所以多个进程同时读也是可以的，但是当写进程需要写数据的时候为了保证数据的一致性，所有读的进程都不能读数据，否则读到的数据可能是一半是旧的，一半是新的，这样就乱了。所以为了防止读数据的时候写入新的数据，在读数据的时候就必须对文件加锁，但是如果有两个进程要同时读，另一个进程就只能等待，从性能上讲，是浪费时间。所以这是要用到读写锁，读写锁的出现有效地解决了多进程并行读的问题，这样每个进程在读的时候需要申请读锁，进程之间相互不干扰。如果有进程要写数据，需要申请写锁，如果有读锁或者写锁存在，那么只能等待所有的锁都解锁了才可以进行写操作。有一点值得注意的是，读锁是所有进程共享的，但是写锁是互斥的。

## 记录锁

为了增加同步的性能，可以在读写锁的基础上进一步细分被锁对象的粒度。比如说写操作是针对文件的前1k字节，但是读操作是针对文件的后1k字节，这样就可以对文件的前1k上写锁，后1k上读锁，这样读和写就可以并发进行了，文件锁是记录锁的一个特例，记录锁针对的是文件中的某一部分内容，如果记录锁将整个文件上锁，这时候的记录锁就是一个文件锁。

# 三十四、Linux程序典型内存布局

![1566374936321](C:\Users\LENOVO\AppData\Roaming\Typora\typora-user-images\1566374936321.png)

# 三十五、C++和++C区别

1、从使用的角度来说：c++是先使用，后自增，++c是先自增，后使用

2、从系统的角度来说：c++表示取c的地址，把他放入寄存器中，然后增加内存中的c，使用寄存器中的值，对于++c表示取c的地址，然后把他放入寄存器中，很显然++c的效率要比c++高，因为c++会生成一个临时变量。

3、如果不需要返回自增后之前的值，那么c++和++c的效果是一样的，但是要优先使用++c，效率高。

# 三十六、lambda表达式

```c++
[函数对象参数](操作符重载函数参数)mutable或exception声明 ->返回值类型{函数体}
```

**函数对象参数**

```c++
空：没有使用任何的函数对象参数。
= ：函数体内可以使用lambda所在作用域范围内所有可见的局部变量，并且是值传递。
& ：函数体内可以使用lambda所在作用域范围内所有可见的局部变量，并且是引用传递。
a ：将a按值传递，但是a的默认是const的，可以添加mutable修饰后变为普通的。
&a：将a按引用传递。
a，&b：将a按值传递，b按引用传递。
=，&a，&b：除了a和b，其他参数均按值传递。
&，a，b：除了a和b，其他参数均按引用传递。
this：函数体重可以使用lambda所在类中的所有成员变量
```

**操作符重载函数参数**

表示重载的()操作符的参数，没有参数的时候这个可以省略。

**mutable或exception声明**

按值传递函数对象参数时，加上mutable修饰可以修改值传递进来的拷贝。exception声明用于指定函数抛出的异常，如抛出整形的异常可以使用throw进行捕获。

**->返回值类型**

标识函数返回值的类型，当返回值为void或者函数同种只有一处return的地方，这部分可以省略。

**{函数体}**

表示函数的实现，这部分不可以省略，但是函数体可以为空。

# 三十七、什么是右值？

左值和右值是编译器和程序中经常出现的词汇，在C++中被广泛认同的说法就是可以取地址的、有名字的就是左值，没有地址的，不能取取名字的就是右值。

在C++11中，右值由纯右值和将亡值组成。

**纯右值**，用于辨识临时变量和一个不跟对象有关联的值，比如说非引用返回的函数返回值，运算表达式、不跟对象关联的字面量值（true、false、常量等）、类型转换函数的返回值，lambda表达式。

**将亡值**，是C++11新增的跟右值引用相关的表达式，这样表达式通常是将要被移动的对象，比如说返回右值引用T&&的函数的返回值，move库函数的返回值，转换为T&&的类型转换函数的返回值。

除了纯右值和将亡值剩余的所有值都是左值。

# 三十八、协议头（手撕）



------------------



# 三十九、怎么实现线程安全**★★★**

线程安全就是多个执行流同时对临界资源  进行操作而不会造成数据的二义性，实现线程安全的方法通常为同步与互斥。

同步就是资源访问的合理，对临界资源访问的时许可控，通过等待与唤醒来实现。

互斥是资源访问的安全性，保证对临界资源同一时间的唯一访问性。

C++中STL的容器都是非线程安全的，因为当初设计STL的时候就是为了追求性能，所以舍弃了线程安全这一块，但是用户可以自己添加线程安全机制。

## 互斥的实现：

互斥锁的实际就是一个只有0和1的计数器，加锁和解锁是一个原子的操作，当一个线程对资源进行加锁操作后，其他的线程如果要使用这份资源就只能等待之前的线程进行解锁操作后才可以得到锁，继续操作，互斥锁需要注意的是锁必须由加锁的线程进行解锁，如果加锁的线程不进行解锁，那么其他线程将永远获取不到锁。所以要在加锁之后所有有可能退出的位置进行解锁，（定义-初始化锁-加解锁-销毁）。在使用锁的时候要注意死锁问题。

## 死锁

### 死锁的产生要满足四个条件

互斥条件，同时只能有一个线程对资源进行操作，比如说打印机等，不可剥夺条件，指的是当前线程所拥有的资源不能被其他县城强制申请走，请求与保持条件，指的是一个线程已经拥有了资源，但是还有申请其他资源，但是资源申请不到，自己所占有的资源也不释放，环路等待条件，可以说是线程的一个等待队列，p1要申请p2所占有的资源，同时也不释放自己的资源，p2也要申请p1的资源，同时也不对自己的资源进行释放，这样就形成了线程的等待环。

### 死锁的预防

死锁的预防就是破坏死锁产生的必要条件：

破坏互斥条件，让线程共享一份资源，但是有些资源的属性就是同时只能给一个线程使用，不能共享。

破坏不可剥夺条件，要求线程如果申请资源失败就要释放自己所有的资源，但是这样会降低系统的性能

破坏请求与保持条件，让线程一次性将自己需要的和可能会用到的资源申请完，这样可能会出现一种情况就是线程无法预知自己需要什么资源，并且线程可能会长期占有可能用不到的资源。

破坏循环等待条件，将资源进行分类、编号，线程按照排好的顺序进行申请，这个存在的问题是资源分类和编号是困难的，并且维持相应的序列也可能是困难的。

### 死锁的避免

死锁避免可以使用著名的银行家算法，

#### 银行家算法

可以把操作系统看做是银行家，资源看做是资金，进程相当于顾客。

当一个顾客对资金的最大需求量不大于银行的库存的时候是可以接待这个顾客的。

顾客可以选择分期贷款，但是贷款总金额不能超过最大需求量

当银行家的库存不能满足顾客的需求的时候，要对各科的贷款进行推迟支付，但是总能使顾客在有限的时间内获得贷款，

当顾客获得了所需要的资源后，要有在一定的时间内归还所有资金的能力

对于操作系统来说，是这样的。

当一个线程申请资源的时候，首先要测试这个线程对资源的最大需求量，如果系统中存在的资源可以满足要求，就按照当前的申请量进行分配资源，否则就要推迟分配。当线程在执行中持续申请资源，要先测试线程本次申请的资源是否已经超过了该资源所剩的总数，如果超过了就要推迟分配，如果可以就按当前的申请量进行资源分配。



# 四十、线程同步的方式

# 四十一、C++和C的区别

# 四十二、main函数前执行和main函数结束后执行





# n、

# 提问环节

1、实习进去之后会接触到什么技术？